{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from driver.MongoDriver import MongoDriver\n",
    "import util.Constants as const\n",
    "from service.DataPreparationHandler import get_data\n",
    "from util.PandasUtils import PandasUtils\n",
    "import DisplayHelper\n",
    "from DisplayHelper import *\n",
    "from pprint import PrettyPrinter\n",
    "from util.DataPreparationUtils import *\n",
    "from stubutils.StubUtils import open_file\n",
    "import pandas\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "from sklearn.preprocessing import OneHotEncoder as ohe\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "mpl.style.use( 'ggplot' )\n",
    "sns.set_style( 'white' )\n",
    "pylab.rcParams[ 'figure.figsize' ] = 8 , 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructor called\n"
     ]
    }
   ],
   "source": [
    "db_instance = MongoDriver.get_instance().get_db_instance(const.DB_INSTANCE)\n",
    "data = get_data(db_instance, 'normalized_data')\n",
    "dataframe = PandasUtils.get_dataframe(data, const.JSON_STRUCTURE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframe['search_model'] = dataframe.apply(lambda row: get_id_by_make_name(row['search_model']),axis=1).astype(int)\n",
    "dataframe['search_rigion'] = dataframe.apply(lambda row: get_id_by_region_name(row['search_rigion']),axis=1).astype(int)\n",
    "dataframe['search_city'] = dataframe.apply(lambda row: get_id_by_city_name(row['search_city']),axis=1).astype(int)\n",
    "dataframe['search_country'] = dataframe.apply(lambda row: get_id_by_name_simple(const.COUNTRY_ID_MAPPING_JSON_ROUTE, row['search_country']),axis=1).astype(int)\n",
    "dataframe['search_marka'] = dataframe.apply(lambda row: get_id_by_name_simple(const.MODELS_ID_MAPPING_JSON_ROUTE, row['search_marka']),axis=1).astype(int)\n",
    "dataframe['search_wheel'] = dataframe.apply(lambda row: get_id_by_name_simple(const.WHEELS_ID_MAPPING_JSON_ROUTE, row['search_wheel']),axis=1).astype(int)\n",
    "dataframe['search_body'] = dataframe.apply(lambda row: get_id_by_name_simple(const.BODIES_ID_MAPPING_JSON_ROUTE, row['search_body']),axis=1).astype(int)\n",
    "dataframe['search_transmission'] = dataframe.apply(lambda row: get_id_by_name_simple(const.TRANSMISSIONS_ID_MAPPING_JSON_ROUTE, row['search_transmission']),axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframe['search_marka'] = dataframe.apply(lambda row: get_id_by_name_simple(const.MODELS_ID_MAPPING_JSON_ROUTE, row['search_marka']),axis=1)\n",
    "dataframe = pandas.get_dummies(dataframe, columns=[\"search_model\", \"search_rigion\", \"search_country\", \"search_wheel\", \"search_body\", \"search_transmission\"], \n",
    "                   prefix=[\"model\", \"rigion\", \"country\", \"wheel\", \"body\", \"transmission\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create delta columns for fields \"from\" and \"to\"\n",
    "dataframe['search_volume'] = (dataframe['search_volume_to'] + dataframe['search_volume_from'])/2\n",
    "dataframe['search_milleage'] = (dataframe['search_milleage_to'] + dataframe['search_milleage_from'])/2\n",
    "dataframe['search_price'] = (dataframe['search_price_to'] + dataframe['search_price_from'])/2\n",
    "dataframe['search_year'] = (dataframe['search_year_to'] + dataframe['search_year_from'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'values': [1201130111.0, 1274144891.5, 1351174153.0, 1414614207.0, 1500866531.0], 'name': 'last_login'}\n",
      "{'values': [451.5, 3759.5, 5172.0, 6634.25, 7994.0], 'name': 'search_volume'}\n",
      "{'values': [53586.0, 457799.0, 616495.0, 817742.5, 995650.0], 'name': 'search_milleage'}\n",
      "{'values': [1961.5, 1985.5, 1994.5, 2005.0, 2016.0], 'name': 'search_year'}\n",
      "{'values': [2210.0, 182155.0, 257996.0, 331533.25, 399227.5], 'name': 'search_price'}\n"
     ]
    }
   ],
   "source": [
    "for column in const.NUMERIC_COLUMNS_REQUIRE_ANALYSIS:\n",
    "        quartiles = get_percentiles_for_numeric_column(dataframe,column)\n",
    "        print quartiles\n",
    "        dataframe.loc[ dataframe[column] <= quartiles['values'][1], column] = 0\n",
    "        dataframe.loc[(dataframe[column] > quartiles['values'][1]) & (dataframe[column] <= quartiles['values'][2]), column] = 1\n",
    "        dataframe.loc[(dataframe[column] > quartiles['values'][2]) & (dataframe[column] <= quartiles['values'][3]), column]   = 2\n",
    "        dataframe.loc[ dataframe[column] > quartiles['values'][3], column] = 3\n",
    "        dataframe[column] = dataframe[column].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframe.loc[ dataframe['search_volume'] <= 3760, 'search_volume'] = 0\n",
    "dataframe.loc[(dataframe['search_volume'] > 3760) & (dataframe['search_volume'] <= 5172), 'search_volume'] = 1\n",
    "dataframe.loc[(dataframe['search_volume'] > 5172) & (dataframe[column] <= 6634), 'search_volume']   = 2\n",
    "dataframe.loc[ dataframe['search_volume'] > 6634, 'search_volume'] = 3\n",
    "dataframe['search_volume'] = dataframe['search_volume'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Drop unhandled columns\n",
    "for column in const.COLUMNS_TO_DROP:\n",
    "    dataframe = dataframe.drop(column, axis=1)\n",
    "    \n",
    "#dataframe = dataframe.drop(\"search_city\", axis=1)\n",
    "#dataframe = dataframe.drop(\"search_rigion\", axis=1)\n",
    "#dataframe = dataframe.drop(\"search_model\", axis=1)\n",
    "#dataframe = dataframe.drop(\"search_year\", axis=1)\n",
    "#dataframe = dataframe.drop(\"search_volume\", axis=1)\n",
    "#dataframe = dataframe.drop(\"search_milleage\", axis=1)\n",
    "#dataframe = dataframe.drop(\"search_price\", axis=1)\n",
    "#dataframe = dataframe.drop(\"search_year\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframe = dataframe.drop(\"search_city\", axis=1)\n",
    "dataframe = dataframe.drop(\"search_rigion\", axis=1)\n",
    "dataframe = dataframe.drop(\"last_login\", axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_data = dataframe.drop(\"search_marka\", axis=1)          # data: Features\n",
    "Y_data = dataframe[\"search_marka\"]                       # data: Labels\n",
    "for f in X_data.columns: \n",
    "    if X_data[f].dtype=='object': \n",
    "        lbl = preprocessing.LabelEncoder() \n",
    "        lbl.fit(list(X_data[f].values)) \n",
    "        X_data[f] = lbl.transform(list(X_data[f].values))\n",
    "#split data into random \"train\" and \"test\" set \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, test_size=0.2, random_state=0)\n",
    "X_train = X_train.drop('user_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for f in X_train.columns: \n",
    "    if X_train[f].dtype=='object': \n",
    "        lbl = preprocessing.LabelEncoder() \n",
    "        lbl.fit(list(X_train[f].values)) \n",
    "        X_train[f] = lbl.transform(list(X_train[f].values))\n",
    "for f in X_test.columns: \n",
    "    if X_test[f].dtype=='object': \n",
    "        lbl = preprocessing.LabelEncoder() \n",
    "        lbl.fit(list(X_test[f].values)) \n",
    "        X_test[f] = lbl.transform(list(X_test[f].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training finished in 3 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.016666666666666666"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "# Support Vector Machines\n",
    "d1 = datetime.now()\n",
    "param_dist = {'n_estimators':355, 'nthread':22, 'max_depth':7}\n",
    "xg = xgb.XGBClassifier()\n",
    "xg.fit(X_train, Y_train, verbose=True)\n",
    "d2 = datetime.now()\n",
    "delta = d2 - d1\n",
    "print \"training finished in \" + str(delta.seconds) + \" seconds\"\n",
    "X_test_ref = X_test.drop('user_id', axis=1)\n",
    "Y_pred  = xg.predict(X_test_ref)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "         \"user_id\": X_test[\"user_id\"],\n",
    "         \"search_marka\": Y_pred\n",
    "     })\n",
    "submission.to_csv('resource/results_XGB.csv', index=False)\n",
    "accuracy_score(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training finished in 331 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.016666666666666666"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "param_dist = {'n_estimators':7, 'nthread':22, 'max_depth':7}\n",
    "xg = xgb.XGBClassifier()\n",
    "d1 = datetime.now()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, test_size=0.2, random_state=0)\n",
    "X_train = X_train.drop('user_id', axis=1)\n",
    "for i in range(1,60):\n",
    "    X_inner_train, X_inner_test, Y_inner_train, Y_inner_test = train_test_split(X_data, Y_data, test_size=0.2, random_state=0)\n",
    "    X_inner_train = X_inner_train.drop('user_id', axis=1)\n",
    "    xg.fit(X_inner_train, Y_inner_train, verbose=True)\n",
    "d2 = datetime.now()\n",
    "delta = d2 - d1\n",
    "print \"training finished in \" + str(delta.seconds) + \" seconds\"\n",
    "X_test_ref = X_test.drop('user_id', axis=1)\n",
    "Y_pred  = xg.predict(X_test_ref)\n",
    "accuracy_score(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_ref = X_test.drop('user_id', axis=1)\n",
    "xg_train = xgb.DMatrix(X_train, label=Y_train)\n",
    "xg_test = xgb.DMatrix(X_test_ref, label=Y_test)\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 6\n",
    "param['silent'] = 1\n",
    "param['nthread'] = 4\n",
    "# param['num_class'] = 112\n",
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "num_round = 1\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist)\n",
    "# get prediction\n",
    "pred = bst.predict(xg_test)\n",
    "error_rate = np.sum(pred != Y_test) / Y_test.shape[0]\n",
    "print('Test error using softmax = {}'.format(error_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.0166666666667 with parameters {'n_estimators': 1, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0 with parameters {'n_estimators': 1, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0 with parameters {'n_estimators': 1, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0 with parameters {'n_estimators': 1, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0 with parameters {'n_estimators': 1, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0 with parameters {'n_estimators': 1, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0 with parameters {'n_estimators': 1, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0 with parameters {'n_estimators': 1, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0 with parameters {'n_estimators': 1, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0 with parameters {'n_estimators': 1, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0 with parameters {'n_estimators': 1, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0 with parameters {'n_estimators': 1, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0 with parameters {'n_estimators': 1, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0 with parameters {'n_estimators': 1, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0 with parameters {'n_estimators': 2, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0 with parameters {'n_estimators': 2, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0 with parameters {'n_estimators': 2, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0 with parameters {'n_estimators': 2, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0 with parameters {'n_estimators': 2, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0 with parameters {'n_estimators': 2, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0 with parameters {'n_estimators': 2, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0 with parameters {'n_estimators': 2, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0 with parameters {'n_estimators': 2, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0 with parameters {'n_estimators': 2, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0 with parameters {'n_estimators': 2, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0 with parameters {'n_estimators': 2, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0 with parameters {'n_estimators': 2, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0 with parameters {'n_estimators': 2, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0 with parameters {'n_estimators': 3, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0 with parameters {'n_estimators': 3, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0 with parameters {'n_estimators': 3, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0 with parameters {'n_estimators': 3, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0 with parameters {'n_estimators': 3, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0 with parameters {'n_estimators': 3, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0 with parameters {'n_estimators': 3, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0 with parameters {'n_estimators': 3, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0 with parameters {'n_estimators': 3, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0 with parameters {'n_estimators': 3, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0 with parameters {'n_estimators': 3, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0 with parameters {'n_estimators': 3, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0 with parameters {'n_estimators': 3, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0 with parameters {'n_estimators': 3, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0 with parameters {'n_estimators': 4, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0 with parameters {'n_estimators': 4, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0 with parameters {'n_estimators': 4, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0 with parameters {'n_estimators': 4, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0 with parameters {'n_estimators': 4, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0 with parameters {'n_estimators': 4, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0 with parameters {'n_estimators': 4, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0 with parameters {'n_estimators': 4, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0 with parameters {'n_estimators': 4, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0 with parameters {'n_estimators': 4, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0 with parameters {'n_estimators': 4, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0 with parameters {'n_estimators': 4, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0 with parameters {'n_estimators': 4, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0 with parameters {'n_estimators': 4, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0 with parameters {'n_estimators': 5, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0 with parameters {'n_estimators': 5, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0 with parameters {'n_estimators': 5, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0 with parameters {'n_estimators': 5, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0 with parameters {'n_estimators': 5, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0 with parameters {'n_estimators': 5, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0 with parameters {'n_estimators': 5, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0 with parameters {'n_estimators': 5, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0 with parameters {'n_estimators': 5, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0 with parameters {'n_estimators': 5, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0 with parameters {'n_estimators': 5, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0 with parameters {'n_estimators': 5, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0 with parameters {'n_estimators': 5, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0 with parameters {'n_estimators': 5, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0 with parameters {'n_estimators': 6, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0 with parameters {'n_estimators': 6, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0 with parameters {'n_estimators': 6, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0 with parameters {'n_estimators': 6, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0 with parameters {'n_estimators': 6, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0 with parameters {'n_estimators': 6, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0 with parameters {'n_estimators': 6, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0 with parameters {'n_estimators': 6, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0 with parameters {'n_estimators': 6, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0 with parameters {'n_estimators': 6, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0 with parameters {'n_estimators': 6, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0 with parameters {'n_estimators': 6, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0 with parameters {'n_estimators': 6, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0 with parameters {'n_estimators': 6, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0 with parameters {'n_estimators': 7, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 7, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 7, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 7, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 7, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 7, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 7, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 7, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 7, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 7, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 7, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 7, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 7, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 7, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0 with parameters {'n_estimators': 8, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 8, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 8, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 8, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 8, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 8, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 8, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 8, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 8, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 8, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 8, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 8, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 8, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 8, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0 with parameters {'n_estimators': 9, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 9, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 9, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 9, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 9, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 9, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 9, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 9, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 9, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 9, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 9, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 9, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 9, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 9, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0 with parameters {'n_estimators': 10, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0 with parameters {'n_estimators': 10, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0 with parameters {'n_estimators': 10, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0 with parameters {'n_estimators': 10, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0 with parameters {'n_estimators': 10, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0 with parameters {'n_estimators': 10, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0 with parameters {'n_estimators': 10, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0 with parameters {'n_estimators': 10, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0 with parameters {'n_estimators': 10, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0 with parameters {'n_estimators': 10, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0 with parameters {'n_estimators': 10, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0 with parameters {'n_estimators': 10, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0 with parameters {'n_estimators': 10, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0 with parameters {'n_estimators': 10, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0 with parameters {'n_estimators': 11, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0 with parameters {'n_estimators': 11, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0 with parameters {'n_estimators': 11, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0 with parameters {'n_estimators': 11, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0 with parameters {'n_estimators': 11, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0 with parameters {'n_estimators': 11, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0 with parameters {'n_estimators': 11, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0 with parameters {'n_estimators': 11, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0 with parameters {'n_estimators': 11, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0 with parameters {'n_estimators': 11, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0 with parameters {'n_estimators': 11, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0 with parameters {'n_estimators': 11, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0 with parameters {'n_estimators': 11, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0 with parameters {'n_estimators': 11, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0 with parameters {'n_estimators': 12, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0 with parameters {'n_estimators': 12, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0 with parameters {'n_estimators': 12, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0 with parameters {'n_estimators': 12, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0 with parameters {'n_estimators': 12, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0 with parameters {'n_estimators': 12, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0 with parameters {'n_estimators': 12, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0 with parameters {'n_estimators': 12, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0 with parameters {'n_estimators': 12, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0 with parameters {'n_estimators': 12, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0 with parameters {'n_estimators': 12, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0 with parameters {'n_estimators': 12, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0 with parameters {'n_estimators': 12, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0 with parameters {'n_estimators': 12, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0 with parameters {'n_estimators': 13, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 13, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 13, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 13, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 13, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 13, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 13, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 13, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 13, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 13, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 13, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 13, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 13, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 13, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0 with parameters {'n_estimators': 14, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 14, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 14, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 14, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 14, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 14, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 14, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 14, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 14, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 14, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 14, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 14, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 14, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 14, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0 with parameters {'n_estimators': 15, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0 with parameters {'n_estimators': 15, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 15, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 15, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 15, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 15, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 15, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 15, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 15, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 15, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 15, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 15, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 15, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 15, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0 with parameters {'n_estimators': 16, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 16, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 16, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 16, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 16, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 16, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 16, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 16, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 16, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 16, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 16, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 16, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 16, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 16, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0 with parameters {'n_estimators': 17, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 17, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 17, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 17, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 17, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 17, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 17, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 17, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 17, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 17, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 17, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 17, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 17, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 17, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0 with parameters {'n_estimators': 18, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 18, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 18, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 18, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 18, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 18, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 18, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 18, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 18, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 18, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 18, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 18, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 18, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 18, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0 with parameters {'n_estimators': 19, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0 with parameters {'n_estimators': 19, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 19, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 19, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 19, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 19, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 19, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 19, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 19, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 19, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 19, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 19, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 19, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 19, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0 with parameters {'n_estimators': 20, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0 with parameters {'n_estimators': 20, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 20, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 20, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 20, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 20, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 20, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 20, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 20, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 20, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 20, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 20, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 20, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 20, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0 with parameters {'n_estimators': 21, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0 with parameters {'n_estimators': 21, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 21, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 21, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 21, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 21, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 21, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 21, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 21, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 21, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 21, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 21, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 21, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 21, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0 with parameters {'n_estimators': 22, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0 with parameters {'n_estimators': 22, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0 with parameters {'n_estimators': 22, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0 with parameters {'n_estimators': 22, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0 with parameters {'n_estimators': 22, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0 with parameters {'n_estimators': 22, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0 with parameters {'n_estimators': 22, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0 with parameters {'n_estimators': 22, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0 with parameters {'n_estimators': 22, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0 with parameters {'n_estimators': 22, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0 with parameters {'n_estimators': 22, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0 with parameters {'n_estimators': 22, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0 with parameters {'n_estimators': 22, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0 with parameters {'n_estimators': 22, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0 with parameters {'n_estimators': 23, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 23, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0 with parameters {'n_estimators': 23, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0 with parameters {'n_estimators': 23, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0 with parameters {'n_estimators': 23, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0 with parameters {'n_estimators': 23, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0 with parameters {'n_estimators': 23, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0 with parameters {'n_estimators': 23, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0 with parameters {'n_estimators': 23, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0 with parameters {'n_estimators': 23, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0 with parameters {'n_estimators': 23, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0 with parameters {'n_estimators': 23, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0 with parameters {'n_estimators': 23, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0 with parameters {'n_estimators': 23, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0 with parameters {'n_estimators': 24, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0 with parameters {'n_estimators': 24, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0 with parameters {'n_estimators': 24, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0 with parameters {'n_estimators': 24, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0 with parameters {'n_estimators': 24, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0 with parameters {'n_estimators': 24, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0 with parameters {'n_estimators': 24, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0 with parameters {'n_estimators': 24, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0 with parameters {'n_estimators': 24, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0 with parameters {'n_estimators': 24, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0 with parameters {'n_estimators': 24, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0 with parameters {'n_estimators': 24, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0 with parameters {'n_estimators': 24, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0 with parameters {'n_estimators': 24, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0 with parameters {'n_estimators': 25, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 25, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 25, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 25, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 25, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 25, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 25, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 25, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 25, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 25, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 25, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 25, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 25, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 25, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0 with parameters {'n_estimators': 26, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0 with parameters {'n_estimators': 26, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0 with parameters {'n_estimators': 26, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 26, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 26, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 26, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 26, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 26, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 26, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 26, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 26, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 26, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 26, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 26, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0 with parameters {'n_estimators': 27, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 27, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 27, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 27, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 27, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 27, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 27, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 27, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 27, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 27, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 27, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 27, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 27, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 27, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0 with parameters {'n_estimators': 28, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 28, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 28, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 28, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 28, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 28, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 28, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 28, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 28, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 28, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 28, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 28, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 28, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 28, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0 with parameters {'n_estimators': 29, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 29, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 29, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 29, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 29, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 29, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 29, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 29, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 29, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 29, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 29, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 29, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 29, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 29, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0 with parameters {'n_estimators': 30, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0 with parameters {'n_estimators': 30, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 30, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 30, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 30, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 30, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 30, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 30, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 30, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 30, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 30, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 30, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 30, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 30, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0 with parameters {'n_estimators': 31, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 31, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 31, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 31, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 31, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 31, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 31, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 31, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 31, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 31, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 31, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 31, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 31, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 31, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0 with parameters {'n_estimators': 32, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 32, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 32, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 32, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 32, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 32, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 32, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 32, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 32, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 32, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 32, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 32, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 32, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 32, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 33, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 33, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 33, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 33, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 33, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 33, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 33, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 33, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 33, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 33, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 33, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 33, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 33, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 33, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 34, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0 with parameters {'n_estimators': 34, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 34, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 34, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 34, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 34, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 34, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 34, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 34, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 34, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 34, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 34, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 34, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 34, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 35, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 35, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 35, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 35, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 35, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 35, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 35, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 35, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 35, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 35, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 35, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 35, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 35, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 35, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 36, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 36, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 36, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 36, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 36, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 36, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 36, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 36, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 36, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 36, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 36, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 36, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 36, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 36, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 37, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 37, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 37, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 37, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 37, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 37, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 37, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 37, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 37, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 37, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 37, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 37, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 37, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 37, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 38, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 38, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 38, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 38, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 38, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 38, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 38, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 38, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 38, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 38, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 38, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 38, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 38, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 38, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 39, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 39, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 39, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 39, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 39, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 39, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 39, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 39, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 39, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 39, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 39, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 39, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 39, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 39, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 40, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 40, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 40, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 40, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 40, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 40, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 40, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 40, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 40, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 40, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 40, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 40, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 40, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 40, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 41, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 41, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 41, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 41, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 41, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 41, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 41, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 41, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 41, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 41, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 41, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 41, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 41, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 41, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 42, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 42, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 42, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 42, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 42, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 42, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 42, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 42, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 42, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 42, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 42, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 42, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 42, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 42, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 43, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 43, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 43, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 43, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 43, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 43, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 43, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 43, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 43, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 43, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 43, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 43, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 43, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 43, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 44, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 44, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 44, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 44, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 44, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 44, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 44, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 44, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 44, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 44, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 44, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 44, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 44, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 44, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 45, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 45, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 45, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 45, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 45, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 45, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 45, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 45, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 45, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 45, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 45, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 45, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 45, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 45, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 46, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 46, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 46, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 46, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 46, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 46, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 46, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 46, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 46, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 46, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 46, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 46, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 46, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 46, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 47, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 47, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 47, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 47, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 47, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 47, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 47, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 47, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 47, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 47, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 47, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 47, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 47, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 47, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 48, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 48, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 48, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 48, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 48, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 48, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 48, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 48, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 48, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 48, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 48, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 48, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 48, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 48, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 49, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 49, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 49, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 49, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 49, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 49, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 49, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 49, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 49, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 49, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 49, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 49, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 49, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 49, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 50, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 50, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 50, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 50, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 50, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 50, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 50, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 50, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 50, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 50, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 50, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 50, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 50, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 50, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 51, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 51, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 51, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 51, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 51, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 51, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 51, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 51, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 51, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 51, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 51, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 51, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 51, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 51, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 52, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 52, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 52, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 52, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 52, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 52, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 52, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 52, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 52, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 52, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 52, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 52, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 52, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 52, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 53, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 53, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 53, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 53, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 53, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 53, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 53, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 53, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 53, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 53, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 53, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 53, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 53, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 53, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 54, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 54, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 54, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 54, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 54, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 54, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 54, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 54, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 54, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 54, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 54, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 54, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 54, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 54, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 55, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 55, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 55, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 55, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 55, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 55, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 55, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 55, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 55, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 55, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 55, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 55, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 55, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 55, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 56, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 56, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 56, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 56, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 56, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 56, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 56, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 56, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 56, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 56, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 56, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 56, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 56, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 56, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 57, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 57, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 57, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 57, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 57, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 57, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 57, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 57, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 57, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 57, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 57, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 57, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 57, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 57, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 58, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 58, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 58, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 58, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 58, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 58, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 58, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 58, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 58, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 58, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 58, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 58, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 58, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 58, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 59, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 59, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 59, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 59, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 59, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 59, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 59, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 59, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 59, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 59, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 59, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 59, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 59, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 59, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 60, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 60, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 60, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 60, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 60, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 60, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 60, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 60, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 60, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 60, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 60, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 60, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 60, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 60, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 61, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 61, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 61, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 61, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 61, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 61, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 61, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 61, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 61, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 61, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 61, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 61, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 61, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 61, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 62, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 62, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 62, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 62, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 62, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 62, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 62, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 62, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 62, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 62, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 62, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 62, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 62, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 62, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 63, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 63, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 63, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 63, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 63, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 63, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 63, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 63, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 63, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 63, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 63, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 63, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 63, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 63, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 64, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 64, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 64, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 64, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 64, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 64, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 64, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 64, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 64, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 64, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 64, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 64, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 64, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 64, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 65, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 65, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 65, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 65, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 65, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 65, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 65, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 65, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 65, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 65, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 65, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 65, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 65, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 65, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 66, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 66, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 66, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 66, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 66, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 66, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 66, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 66, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 66, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 66, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 66, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 66, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 66, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 66, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 67, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 67, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 67, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 67, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 67, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 67, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 67, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 67, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 67, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 67, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 67, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 67, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 67, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 67, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 68, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 68, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 68, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 68, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 68, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 68, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 68, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 68, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 68, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 68, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 68, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 68, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 68, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 68, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 69, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 69, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 69, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 69, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 69, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 69, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 69, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 69, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 69, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 69, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 69, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 69, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 69, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 69, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 70, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 70, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 70, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 70, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 70, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 70, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 70, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 70, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 70, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 70, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 70, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 70, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 70, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 70, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 71, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 71, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 71, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 71, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 71, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 71, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 71, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 71, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 71, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 71, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 71, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 71, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 71, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 71, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 72, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 72, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 72, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 72, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 72, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 72, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 72, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 72, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 72, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 72, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 72, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 72, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 72, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 72, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 73, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 73, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 73, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 73, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 73, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 73, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 73, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 73, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 73, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 73, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 73, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 73, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 73, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 73, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 74, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 74, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 74, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 74, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 74, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 74, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 74, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 74, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 74, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 74, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 74, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 74, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 74, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 74, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 75, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 75, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 75, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 75, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 75, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 75, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 75, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 75, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 75, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 75, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 75, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 75, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 75, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 75, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 76, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 76, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 76, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 76, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 76, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 76, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 76, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 76, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 76, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 76, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 76, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 76, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 76, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 76, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 77, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 77, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 77, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 77, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 77, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 77, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 77, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 77, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 77, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 77, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 77, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 77, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 77, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 77, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 78, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 78, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 78, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 78, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 78, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 78, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 78, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 78, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 78, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 78, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 78, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 78, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 78, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 78, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 79, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 79, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 79, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 79, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 79, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 79, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 79, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 79, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 79, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 79, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 79, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 79, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 79, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 79, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 80, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 80, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 80, 'nthread': 22, 'max_depth': 3}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 80, 'nthread': 22, 'max_depth': 4}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 80, 'nthread': 22, 'max_depth': 5}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 80, 'nthread': 22, 'max_depth': 6}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 80, 'nthread': 22, 'max_depth': 7}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 80, 'nthread': 22, 'max_depth': 8}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 80, 'nthread': 22, 'max_depth': 9}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 80, 'nthread': 22, 'max_depth': 10}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 80, 'nthread': 22, 'max_depth': 11}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 80, 'nthread': 22, 'max_depth': 12}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 80, 'nthread': 22, 'max_depth': 13}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 80, 'nthread': 22, 'max_depth': 14}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 81, 'nthread': 22, 'max_depth': 1}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 81, 'nthread': 22, 'max_depth': 2}\n",
      "accuracy 0.0166666666667 with parameters {'n_estimators': 81, 'nthread': 22, 'max_depth': 3}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-80535913a28d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mparam_dist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'n_estimators'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'nthread'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m22\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'max_depth'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mxg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparam_dist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mxg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mX_test_ref\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'user_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mY_pred\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mxg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Anaconda2\\lib\\site-packages\\xgboost-0.6-py2.7.egg\\xgboost\\sklearn.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose)\u001b[0m\n\u001b[1;32m    462\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m                               verbose_eval=verbose)\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Anaconda2\\lib\\site-packages\\xgboost-0.6-py2.7.egg\\xgboost\\training.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Anaconda2\\lib\\site-packages\\xgboost-0.6-py2.7.egg\\xgboost\\training.pyc\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Anaconda2\\lib\\site-packages\\xgboost-0.6-py2.7.egg\\xgboost\\core.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "# Support Vector Machines\n",
    "for i in range(1,150):\n",
    "    for j in range(1,15):\n",
    "        param_dist = {'n_estimators':i, 'nthread':22, 'max_depth':j}\n",
    "        xg = xgb.XGBClassifier(**param_dist)\n",
    "        xg.fit(X_train, Y_train, verbose=True)\n",
    "        X_test_ref = X_test.drop('user_id', axis=1)\n",
    "        Y_pred  = xg.predict(X_test_ref)\n",
    "        print \"accuracy {} with parameters {}\".format(accuracy_score(Y_test, Y_pred), param_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_ref = X_test.drop('user_id', axis=1)\n",
    "xg_train = xgb.DMatrix(X_train.values, label=Y_train.values)\n",
    "xg_test = xgb.DMatrix(X_test_ref.values, label=Y_test)\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 6\n",
    "param['silent'] = 1\n",
    "param['nthread'] = 4\n",
    "param['num_class'] = len(dataframe['search_marka'].unique())\n",
    "\n",
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "num_round = 5\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist)\n",
    "# get prediction\n",
    "pred = bst.predict(xg_test)\n",
    "error_rate = np.sum(pred != Y_test) / Y_test.shape[0]\n",
    "print('Test error using softmax = {}'.format(error_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training finished in 0 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.016666666666666666"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support Vector Machines\n",
    "xg = rfc()\n",
    "d3 = datetime.now()\n",
    "xg.fit(X_train, Y_train)\n",
    "d4 = datetime.now()\n",
    "delta1 = d4 - d3\n",
    "print \"training finished in \" + str(delta1.seconds) + \" seconds\"\n",
    "X_test_rfc_ref = X_test.drop('user_id', axis=1)\n",
    "Y_rfc_pred  = xg.predict(X_test_rfc_ref)\n",
    "\n",
    "submission_rfc = pd.DataFrame({\n",
    "         \"user_id\": X_test[\"user_id\"],\n",
    "         \"search_marka\": Y_rfc_pred\n",
    "     })\n",
    "submission_rfc.to_csv('resource/results_RFC.csv', index=False)\n",
    "accuracy_score(Y_test, Y_rfc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "transform() takes exactly 2 arguments (3 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-45c6ec862808>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0menc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mohe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0menc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'search_marka'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'search_model'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: transform() takes exactly 2 arguments (3 given)"
     ]
    }
   ],
   "source": [
    "enc = ohe()\n",
    "enc.transform(dataframe['search_marka'], dataframe['search_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97997496871088863"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred  = xg.predict(X_train)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "         \"user_id\": X_train[\"user_id\"],\n",
    "         \"search_marka\": Y_pred\n",
    "     })\n",
    "submission.to_csv('resource/results_XGB.csv', index=False)\n",
    "xg.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "plot_histograms() takes exactly 4 arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-e08f45a664f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'search_year_from'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_histograms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: plot_histograms() takes exactly 4 arguments (1 given)"
     ]
    }
   ],
   "source": [
    "result = preprocessing.scale(dataframe['search_year_from'])\n",
    "plot_histograms(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataframe['search_marka'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_login</th>\n",
       "      <th>search_city</th>\n",
       "      <th>search_condition</th>\n",
       "      <th>search_engine</th>\n",
       "      <th>search_marka</th>\n",
       "      <th>search_milleage_from</th>\n",
       "      <th>search_milleage_to</th>\n",
       "      <th>search_price_from</th>\n",
       "      <th>search_price_to</th>\n",
       "      <th>search_text</th>\n",
       "      <th>...</th>\n",
       "      <th>body_8</th>\n",
       "      <th>body_9</th>\n",
       "      <th>body_10</th>\n",
       "      <th>body_11</th>\n",
       "      <th>transmission_1</th>\n",
       "      <th>transmission_2</th>\n",
       "      <th>search_volume</th>\n",
       "      <th>search_milleage</th>\n",
       "      <th>search_price</th>\n",
       "      <th>search_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.383336e+09</td>\n",
       "      <td>17</td>\n",
       "      <td>search_condition</td>\n",
       "      <td>engine</td>\n",
       "      <td>0</td>\n",
       "      <td>749039</td>\n",
       "      <td>914420</td>\n",
       "      <td>348318</td>\n",
       "      <td>367905</td>\n",
       "      <td>search_text</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1668.0</td>\n",
       "      <td>831729.5</td>\n",
       "      <td>358111.5</td>\n",
       "      <td>2008.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.378692e+09</td>\n",
       "      <td>14</td>\n",
       "      <td>search_condition</td>\n",
       "      <td>engine</td>\n",
       "      <td>0</td>\n",
       "      <td>878037</td>\n",
       "      <td>925468</td>\n",
       "      <td>241480</td>\n",
       "      <td>356784</td>\n",
       "      <td>search_text</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1873.5</td>\n",
       "      <td>901752.5</td>\n",
       "      <td>299132.0</td>\n",
       "      <td>1997.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.238856e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>search_condition</td>\n",
       "      <td>engine</td>\n",
       "      <td>0</td>\n",
       "      <td>500878</td>\n",
       "      <td>680176</td>\n",
       "      <td>77299</td>\n",
       "      <td>237883</td>\n",
       "      <td>search_text</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3097.0</td>\n",
       "      <td>590527.0</td>\n",
       "      <td>157591.0</td>\n",
       "      <td>1988.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.284402e+09</td>\n",
       "      <td>17</td>\n",
       "      <td>search_condition</td>\n",
       "      <td>engine</td>\n",
       "      <td>0</td>\n",
       "      <td>376348</td>\n",
       "      <td>705861</td>\n",
       "      <td>233231</td>\n",
       "      <td>367141</td>\n",
       "      <td>search_text</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7557.5</td>\n",
       "      <td>541104.5</td>\n",
       "      <td>300186.0</td>\n",
       "      <td>2004.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.391544e+09</td>\n",
       "      <td>10</td>\n",
       "      <td>search_condition</td>\n",
       "      <td>engine</td>\n",
       "      <td>0</td>\n",
       "      <td>232131</td>\n",
       "      <td>569202</td>\n",
       "      <td>336394</td>\n",
       "      <td>359629</td>\n",
       "      <td>search_text</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5681.0</td>\n",
       "      <td>400666.5</td>\n",
       "      <td>348011.5</td>\n",
       "      <td>1991.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     last_login  search_city  search_condition search_engine  search_marka  \\\n",
       "0  1.383336e+09           17  search_condition        engine             0   \n",
       "1  1.378692e+09           14  search_condition        engine             0   \n",
       "2  1.238856e+09            2  search_condition        engine             0   \n",
       "3  1.284402e+09           17  search_condition        engine             0   \n",
       "4  1.391544e+09           10  search_condition        engine             0   \n",
       "\n",
       "   search_milleage_from  search_milleage_to  search_price_from  \\\n",
       "0                749039              914420             348318   \n",
       "1                878037              925468             241480   \n",
       "2                500878              680176              77299   \n",
       "3                376348              705861             233231   \n",
       "4                232131              569202             336394   \n",
       "\n",
       "   search_price_to  search_text     ...       body_8  body_9  body_10  \\\n",
       "0           367905  search_text     ...            0       0        0   \n",
       "1           356784  search_text     ...            0       0        0   \n",
       "2           237883  search_text     ...            0       0        0   \n",
       "3           367141  search_text     ...            1       0        0   \n",
       "4           359629  search_text     ...            1       0        0   \n",
       "\n",
       "   body_11  transmission_1  transmission_2  search_volume  search_milleage  \\\n",
       "0        0               1               0         1668.0         831729.5   \n",
       "1        0               1               0         1873.5         901752.5   \n",
       "2        0               1               0         3097.0         590527.0   \n",
       "3        0               1               0         7557.5         541104.5   \n",
       "4        0               1               0         5681.0         400666.5   \n",
       "\n",
       "   search_price  search_year  \n",
       "0      358111.5       2008.5  \n",
       "1      299132.0       1997.5  \n",
       "2      157591.0       1988.0  \n",
       "3      300186.0       2004.5  \n",
       "4      348011.5       1991.0  \n",
       "\n",
       "[5 rows x 151 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     last_login  search_body  search_city  search_country  search_marka  \\\n",
      "0             2            5           17               1            96   \n",
      "1             2            5           14               1            26   \n",
      "2             0            1            2               2            70   \n",
      "3             1            8           17               2           100   \n",
      "4             2            8           10               2            71   \n",
      "5             3            7           23               2            41   \n",
      "6             3            2           53               2            78   \n",
      "7             1            3           14               2            45   \n",
      "8             0            1           32               2           126   \n",
      "9             0            6            1               1           103   \n",
      "10            3           10            1               1            31   \n",
      "11            3            8            1               1           131   \n",
      "12            0            5           13               1           129   \n",
      "13            2           11            1               1            14   \n",
      "14            0            6            4               2            96   \n",
      "15            1            9            6               1            61   \n",
      "16            3            8            5               1            37   \n",
      "17            2            2            3               1            56   \n",
      "18            1           10            1               2            83   \n",
      "19            1            4            2               1            57   \n",
      "20            1            7           35               2           118   \n",
      "21            1            2            4               1           121   \n",
      "22            2            3           14               2           107   \n",
      "23            3            9            6               1            14   \n",
      "24            3            9            9               1           101   \n",
      "25            2            7           24               1           112   \n",
      "26            3            8           51               2            87   \n",
      "27            1            2           35               2            84   \n",
      "28            3            7           13               1            29   \n",
      "29            2           10           16               2           100   \n",
      "..          ...          ...          ...             ...           ...   \n",
      "269           3            6           19               1           101   \n",
      "270           2            8           18               1            36   \n",
      "271           2            1           24               1            28   \n",
      "272           1           11            1               1            80   \n",
      "273           3            1           11               1            69   \n",
      "274           2           11            5               2            96   \n",
      "275           1            1           13               1            45   \n",
      "276           0            6           11               1           115   \n",
      "277           1            5            1               2             5   \n",
      "278           1            6           44               2            89   \n",
      "279           2            7            2               2            59   \n",
      "280           3            7            7               2            31   \n",
      "281           2            1           18               2           123   \n",
      "282           1           10           15               1            14   \n",
      "283           0           10            1               2           107   \n",
      "284           1           11            2               2            61   \n",
      "285           2            7           11               1            52   \n",
      "286           0           11           19               2            28   \n",
      "287           0           11           27               2            91   \n",
      "288           2            9            4               2            21   \n",
      "289           2            1            4               2            61   \n",
      "290           0            4            4               1             6   \n",
      "291           2            9            8               2           120   \n",
      "292           1            3            8               1            16   \n",
      "293           0            6           85               2            84   \n",
      "294           3            2           20               1            11   \n",
      "295           0            8           22               1            35   \n",
      "296           0            7            1               1            42   \n",
      "297           1            8            1               1           129   \n",
      "298           1           10           26               1           105   \n",
      "\n",
      "     search_model  search_rigion  search_transmission  search_wheel  user_id  \\\n",
      "0               3              2                    1             2        1   \n",
      "1               3              3                    1             1        2   \n",
      "2              82             50                    1             3        3   \n",
      "3               1             39                    1             2        4   \n",
      "4               7             48                    1             1        5   \n",
      "5               7             51                    2             3        6   \n",
      "6              27             28                    1             2        7   \n",
      "7               2             80                    1             3        8   \n",
      "8               7             15                    1             1        9   \n",
      "9               8              1                    1             1       10   \n",
      "10              1              1                    2             3       11   \n",
      "11              2              1                    2             1       12   \n",
      "12              3              6                    1             2       13   \n",
      "13              1              1                    2             3       14   \n",
      "14             10             10                    1             2       15   \n",
      "15              2              6                    1             1       16   \n",
      "16              2              7                    1             2       17   \n",
      "17              1              7                    1             2       18   \n",
      "18             16             14                    1             1       19   \n",
      "19              1              4                    1             2       20   \n",
      "20              2             30                    1             1       21   \n",
      "21              1              6                    2             2       22   \n",
      "22             90             77                    1             3       23   \n",
      "23              2              7                    2             3       24   \n",
      "24              5              7                    1             3       25   \n",
      "25              5              2                    1             2       26   \n",
      "26              9             65                    1             1       27   \n",
      "27              3             11                    1             3       28   \n",
      "28             16              5                    2             1       29   \n",
      "29              1             45                    2             3       30   \n",
      "..            ...            ...                  ...           ...      ...   \n",
      "269             6              5                    2             2      270   \n",
      "270             3              3                    2             2      271   \n",
      "271             2              2                    1             1      272   \n",
      "272             1              3                    2             1      273   \n",
      "273            15              7                    1             2      274   \n",
      "274             4             20                    2             3      275   \n",
      "275            74              5                    2             3      276   \n",
      "276             1              7                    1             2      277   \n",
      "277             2             41                    2             3      278   \n",
      "278             2              6                    2             1      279   \n",
      "279             1             45                    2             3      280   \n",
      "280             1             76                    1             1      281   \n",
      "281             2             35                    2             2      282   \n",
      "282             1              7                    2             3      283   \n",
      "283             3              2                    1             3      284   \n",
      "284             2             26                    2             1      285   \n",
      "285             4              4                    1             1      286   \n",
      "286             1             43                    2             2      287   \n",
      "287             4             61                    1             2      288   \n",
      "288            17             19                    2             2      289   \n",
      "289             2             17                    2             1      290   \n",
      "290            10              4                    1             1      291   \n",
      "291             1             24                    2             1      292   \n",
      "292             2              6                    2             1      293   \n",
      "293            11             31                    2             2      294   \n",
      "294             3              6                    1             2      295   \n",
      "295             1              4                    1             2      296   \n",
      "296             1              1                    1             2      297   \n",
      "297             2              2                    1             1      298   \n",
      "298             3              4                    1             3      299   \n",
      "\n",
      "     search_volume  search_milleage  search_price  search_year  \n",
      "0                0                3             3            3  \n",
      "1                0                3             2            2  \n",
      "2                0                1             0            1  \n",
      "3                3                1             2            2  \n",
      "4                2                0             3            1  \n",
      "5                1                2             1            1  \n",
      "6                1                2             1            3  \n",
      "7                3                2             2            3  \n",
      "8                0                3             2            1  \n",
      "9                1                1             3            0  \n",
      "10               3                1             3            2  \n",
      "11               1                0             1            3  \n",
      "12               1                2             2            2  \n",
      "13               3                0             0            3  \n",
      "14               0                1             3            0  \n",
      "15               2                3             3            3  \n",
      "16               1                2             3            2  \n",
      "17               0                1             2            2  \n",
      "18               3                3             0            3  \n",
      "19               2                3             2            2  \n",
      "20               3                3             3            2  \n",
      "21               0                3             3            1  \n",
      "22               1                0             0            1  \n",
      "23               3                2             3            0  \n",
      "24               3                2             3            0  \n",
      "25               0                1             2            2  \n",
      "26               1                1             2            0  \n",
      "27               1                2             3            0  \n",
      "28               3                0             3            3  \n",
      "29               1                3             2            0  \n",
      "..             ...              ...           ...          ...  \n",
      "269              1                2             3            3  \n",
      "270              0                1             2            0  \n",
      "271              1                2             3            2  \n",
      "272              2                1             1            1  \n",
      "273              1                3             1            2  \n",
      "274              2                1             2            1  \n",
      "275              0                0             3            1  \n",
      "276              1                2             1            3  \n",
      "277              0                2             2            0  \n",
      "278              2                0             2            3  \n",
      "279              1                1             3            0  \n",
      "280              0                0             2            1  \n",
      "281              0                3             1            3  \n",
      "282              1                1             0            1  \n",
      "283              0                3             3            1  \n",
      "284              1                0             3            1  \n",
      "285              2                0             0            2  \n",
      "286              0                3             0            1  \n",
      "287              1                0             1            0  \n",
      "288              2                1             2            0  \n",
      "289              0                3             2            1  \n",
      "290              1                2             1            3  \n",
      "291              0                3             2            0  \n",
      "292              2                2             2            2  \n",
      "293              3                0             3            1  \n",
      "294              3                1             1            2  \n",
      "295              0                3             3            3  \n",
      "296              3                1             0            3  \n",
      "297              3                0             0            3  \n",
      "298              3                0             2            2  \n",
      "\n",
      "[299 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "printer = PrettyPrinter()\n",
    "printer.pprint(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_correlation_map( dataframe )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_login</th>\n",
       "      <th>search_milleage_from</th>\n",
       "      <th>search_milleage_to</th>\n",
       "      <th>search_price_from</th>\n",
       "      <th>search_price_to</th>\n",
       "      <th>search_volume_from</th>\n",
       "      <th>search_volume_to</th>\n",
       "      <th>search_year_from</th>\n",
       "      <th>search_year_to</th>\n",
       "      <th>user_id</th>\n",
       "      <th>search_volume</th>\n",
       "      <th>search_milleage</th>\n",
       "      <th>search_price</th>\n",
       "      <th>search_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.990000e+02</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.347289e+09</td>\n",
       "      <td>488465.541806</td>\n",
       "      <td>742932.829431</td>\n",
       "      <td>200902.591973</td>\n",
       "      <td>303719.210702</td>\n",
       "      <td>3930.284281</td>\n",
       "      <td>6108.317726</td>\n",
       "      <td>1987.324415</td>\n",
       "      <td>2001.558528</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>5019.301003</td>\n",
       "      <td>615699.185619</td>\n",
       "      <td>252310.901338</td>\n",
       "      <td>1994.441472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.776082e+07</td>\n",
       "      <td>291487.259417</td>\n",
       "      <td>223817.709339</td>\n",
       "      <td>116748.924709</td>\n",
       "      <td>88933.634518</td>\n",
       "      <td>2352.715403</td>\n",
       "      <td>1773.052419</td>\n",
       "      <td>16.234805</td>\n",
       "      <td>12.148373</td>\n",
       "      <td>86.458082</td>\n",
       "      <td>1865.765792</td>\n",
       "      <td>234020.185247</td>\n",
       "      <td>93562.283804</td>\n",
       "      <td>12.813351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.201130e+09</td>\n",
       "      <td>2651.000000</td>\n",
       "      <td>83537.000000</td>\n",
       "      <td>949.000000</td>\n",
       "      <td>2488.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>465.000000</td>\n",
       "      <td>1960.000000</td>\n",
       "      <td>1963.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>451.500000</td>\n",
       "      <td>53586.000000</td>\n",
       "      <td>2210.000000</td>\n",
       "      <td>1961.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.274145e+09</td>\n",
       "      <td>244253.000000</td>\n",
       "      <td>609723.000000</td>\n",
       "      <td>103131.500000</td>\n",
       "      <td>247352.000000</td>\n",
       "      <td>1823.000000</td>\n",
       "      <td>5413.000000</td>\n",
       "      <td>1973.500000</td>\n",
       "      <td>1995.000000</td>\n",
       "      <td>75.500000</td>\n",
       "      <td>3759.500000</td>\n",
       "      <td>457799.000000</td>\n",
       "      <td>182155.000000</td>\n",
       "      <td>1985.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.351174e+09</td>\n",
       "      <td>473300.000000</td>\n",
       "      <td>797842.000000</td>\n",
       "      <td>185065.000000</td>\n",
       "      <td>332748.000000</td>\n",
       "      <td>3965.000000</td>\n",
       "      <td>6697.000000</td>\n",
       "      <td>1986.000000</td>\n",
       "      <td>2005.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>5172.000000</td>\n",
       "      <td>616495.000000</td>\n",
       "      <td>257996.000000</td>\n",
       "      <td>1994.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.414614e+09</td>\n",
       "      <td>728773.500000</td>\n",
       "      <td>931896.000000</td>\n",
       "      <td>305288.000000</td>\n",
       "      <td>373312.000000</td>\n",
       "      <td>5922.500000</td>\n",
       "      <td>7486.000000</td>\n",
       "      <td>2001.500000</td>\n",
       "      <td>2011.000000</td>\n",
       "      <td>224.500000</td>\n",
       "      <td>6634.250000</td>\n",
       "      <td>817742.500000</td>\n",
       "      <td>331533.250000</td>\n",
       "      <td>2005.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.500867e+09</td>\n",
       "      <td>994869.000000</td>\n",
       "      <td>999148.000000</td>\n",
       "      <td>398572.000000</td>\n",
       "      <td>399883.000000</td>\n",
       "      <td>7990.000000</td>\n",
       "      <td>7998.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>7994.000000</td>\n",
       "      <td>995650.000000</td>\n",
       "      <td>399227.500000</td>\n",
       "      <td>2016.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         last_login  search_milleage_from  search_milleage_to  \\\n",
       "count  2.990000e+02            299.000000          299.000000   \n",
       "mean   1.347289e+09         488465.541806       742932.829431   \n",
       "std    8.776082e+07         291487.259417       223817.709339   \n",
       "min    1.201130e+09           2651.000000        83537.000000   \n",
       "25%    1.274145e+09         244253.000000       609723.000000   \n",
       "50%    1.351174e+09         473300.000000       797842.000000   \n",
       "75%    1.414614e+09         728773.500000       931896.000000   \n",
       "max    1.500867e+09         994869.000000       999148.000000   \n",
       "\n",
       "       search_price_from  search_price_to  search_volume_from  \\\n",
       "count         299.000000       299.000000          299.000000   \n",
       "mean       200902.591973    303719.210702         3930.284281   \n",
       "std        116748.924709     88933.634518         2352.715403   \n",
       "min           949.000000      2488.000000           42.000000   \n",
       "25%        103131.500000    247352.000000         1823.000000   \n",
       "50%        185065.000000    332748.000000         3965.000000   \n",
       "75%        305288.000000    373312.000000         5922.500000   \n",
       "max        398572.000000    399883.000000         7990.000000   \n",
       "\n",
       "       search_volume_to  search_year_from  search_year_to     user_id  \\\n",
       "count        299.000000        299.000000      299.000000  299.000000   \n",
       "mean        6108.317726       1987.324415     2001.558528  150.000000   \n",
       "std         1773.052419         16.234805       12.148373   86.458082   \n",
       "min          465.000000       1960.000000     1963.000000    1.000000   \n",
       "25%         5413.000000       1973.500000     1995.000000   75.500000   \n",
       "50%         6697.000000       1986.000000     2005.000000  150.000000   \n",
       "75%         7486.000000       2001.500000     2011.000000  224.500000   \n",
       "max         7998.000000       2016.000000     2016.000000  299.000000   \n",
       "\n",
       "       search_volume  search_milleage   search_price  search_year  \n",
       "count     299.000000       299.000000     299.000000   299.000000  \n",
       "mean     5019.301003    615699.185619  252310.901338  1994.441472  \n",
       "std      1865.765792    234020.185247   93562.283804    12.813351  \n",
       "min       451.500000     53586.000000    2210.000000  1961.500000  \n",
       "25%      3759.500000    457799.000000  182155.000000  1985.500000  \n",
       "50%      5172.000000    616495.000000  257996.000000  1994.500000  \n",
       "75%      6634.250000    817742.500000  331533.250000  2005.000000  \n",
       "max      7994.000000    995650.000000  399227.500000  2016.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x000000000E528FD0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000000000E746A20>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000000000E846588>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000000000EAE50F0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x00000000104C7748>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000000010591240>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000000010641390>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000000001073DDA0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x00000000108304A8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000000108F3F60>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000000109A84E0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000000010AB3080>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x0000000010B568D0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000000010C5F518>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000000010BB4128>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000000010E14400>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x0000000010ECFEB8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000000011001F60>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000000110CB9B0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000000000D2187B8>]], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAF1CAYAAAAeOhj3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZ4wxxgzA/wNEbRZWlz8x5gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe575b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pandas.DataFrame.hist(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xd21e2e8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFuCAYAAAC2rKADAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4500e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataframe.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_login</th>\n",
       "      <th>search_body</th>\n",
       "      <th>search_country</th>\n",
       "      <th>search_marka</th>\n",
       "      <th>search_transmission</th>\n",
       "      <th>search_wheel</th>\n",
       "      <th>user_id</th>\n",
       "      <th>search_volume</th>\n",
       "      <th>search_milleage</th>\n",
       "      <th>search_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>last_login</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.115474</td>\n",
       "      <td>0.022384</td>\n",
       "      <td>-0.071284</td>\n",
       "      <td>-0.046494</td>\n",
       "      <td>-0.020060</td>\n",
       "      <td>-0.017998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search_body</th>\n",
       "      <td>-0.115474</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001915</td>\n",
       "      <td>-0.055928</td>\n",
       "      <td>-0.049403</td>\n",
       "      <td>-0.033310</td>\n",
       "      <td>-0.036047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search_country</th>\n",
       "      <td>0.022384</td>\n",
       "      <td>-0.001915</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.072432</td>\n",
       "      <td>-0.037934</td>\n",
       "      <td>-0.036925</td>\n",
       "      <td>-0.098124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search_marka</th>\n",
       "      <td>-0.071284</td>\n",
       "      <td>-0.055928</td>\n",
       "      <td>0.072432</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045894</td>\n",
       "      <td>-0.053708</td>\n",
       "      <td>0.038386</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search_transmission</th>\n",
       "      <td>-0.046494</td>\n",
       "      <td>-0.049403</td>\n",
       "      <td>-0.037934</td>\n",
       "      <td>0.045894</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.076887</td>\n",
       "      <td>0.042787</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search_wheel</th>\n",
       "      <td>-0.020060</td>\n",
       "      <td>-0.033310</td>\n",
       "      <td>-0.036925</td>\n",
       "      <td>-0.053708</td>\n",
       "      <td>0.076887</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.021646</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <td>-0.017998</td>\n",
       "      <td>-0.036047</td>\n",
       "      <td>-0.098124</td>\n",
       "      <td>0.038386</td>\n",
       "      <td>0.042787</td>\n",
       "      <td>-0.021646</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search_volume</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search_milleage</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search_price</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     last_login  search_body  search_country  search_marka  \\\n",
       "last_login             1.000000    -0.115474        0.022384     -0.071284   \n",
       "search_body           -0.115474     1.000000       -0.001915     -0.055928   \n",
       "search_country         0.022384    -0.001915        1.000000      0.072432   \n",
       "search_marka          -0.071284    -0.055928        0.072432      1.000000   \n",
       "search_transmission   -0.046494    -0.049403       -0.037934      0.045894   \n",
       "search_wheel          -0.020060    -0.033310       -0.036925     -0.053708   \n",
       "user_id               -0.017998    -0.036047       -0.098124      0.038386   \n",
       "search_volume               NaN          NaN             NaN           NaN   \n",
       "search_milleage             NaN          NaN             NaN           NaN   \n",
       "search_price                NaN          NaN             NaN           NaN   \n",
       "\n",
       "                     search_transmission  search_wheel   user_id  \\\n",
       "last_login                     -0.046494     -0.020060 -0.017998   \n",
       "search_body                    -0.049403     -0.033310 -0.036047   \n",
       "search_country                 -0.037934     -0.036925 -0.098124   \n",
       "search_marka                    0.045894     -0.053708  0.038386   \n",
       "search_transmission             1.000000      0.076887  0.042787   \n",
       "search_wheel                    0.076887      1.000000 -0.021646   \n",
       "user_id                         0.042787     -0.021646  1.000000   \n",
       "search_volume                        NaN           NaN       NaN   \n",
       "search_milleage                      NaN           NaN       NaN   \n",
       "search_price                         NaN           NaN       NaN   \n",
       "\n",
       "                     search_volume  search_milleage  search_price  \n",
       "last_login                     NaN              NaN           NaN  \n",
       "search_body                    NaN              NaN           NaN  \n",
       "search_country                 NaN              NaN           NaN  \n",
       "search_marka                   NaN              NaN           NaN  \n",
       "search_transmission            NaN              NaN           NaN  \n",
       "search_wheel                   NaN              NaN           NaN  \n",
       "user_id                        NaN              NaN           NaN  \n",
       "search_volume                  NaN              NaN           NaN  \n",
       "search_milleage                NaN              NaN           NaN  \n",
       "search_price                   NaN              NaN           NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
