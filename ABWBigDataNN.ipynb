{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\dlwin36\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from driver.MongoDriver import MongoDriver\n",
    "import util.Constants as const\n",
    "from service.DataPreparationHandler import get_data\n",
    "from util.PandasUtils import PandasUtils\n",
    "import DisplayHelper\n",
    "from DisplayHelper import *\n",
    "from pprint import PrettyPrinter\n",
    "from util.DataPreparationUtils import *\n",
    "from stubutils.StubUtils import open_file\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "from sklearn.preprocessing import OneHotEncoder as ohe\n",
    "import xgboost as xgb\n",
    "import numpy\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructor called\n"
     ]
    }
   ],
   "source": [
    "db_instance = MongoDriver.get_instance().get_db_instance(const.DB_INSTANCE)\n",
    "data = get_data(db_instance, 'normalized_data')\n",
    "dataframe = PandasUtils.get_dataframe(data, const.JSON_STRUCTURE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create delta columns for fields \"from\" and \"to\"\n",
    "dataframe['search_volume'] = (dataframe['search_volume_to'] + dataframe['search_volume_from'])/2\n",
    "dataframe['search_milleage'] = (dataframe['search_milleage_to'] + dataframe['search_milleage_from'])/2\n",
    "dataframe['search_price'] = (dataframe['search_price_to'] + dataframe['search_price_from'])/2\n",
    "dataframe['search_year'] = (dataframe['search_year_to'] + dataframe['search_year_from'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for column in const.NUMERIC_COLUMNS_REQUIRE_ANALYSIS:\n",
    "        quartiles = get_percentiles_for_numeric_column(dataframe,column)\n",
    "        dataframe.loc[ dataframe[column] <= quartiles['values'][1], column] = 0\n",
    "        dataframe.loc[(dataframe[column] > quartiles['values'][1]) & (dataframe[column] <= quartiles['values'][2]), column] = 1\n",
    "        dataframe.loc[(dataframe[column] > quartiles['values'][2]) & (dataframe[column] <= quartiles['values'][3]), column]   = 2\n",
    "        dataframe.loc[ dataframe[column] > quartiles['values'][3], column] = 3\n",
    "        dataframe[column] = dataframe[column].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for column_name in const.DATE_COLUMNS:\n",
    "        dataframe[column_name] = dataframe.apply(lambda row: get_season_by_utcdate(row[column_name]),axis=1)\n",
    "        dataframe[column_name] = dataframe[column_name].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframe = pandas.get_dummies(dataframe, columns=[\"search_model\", \"search_rigion\", \"search_country\", \"search_city\", \"search_body\", \"search_transmission\", \"search_wheel\"], \n",
    "                  prefix=[\"model\",\"rigion\", \"country\", \"city\",\"body\",\"transmission\",\"wheel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drop unhandled columns\n",
    "for column in const.COLUMNS_TO_DROP:\n",
    "    dataframe = dataframe.drop(column, axis=1)\n",
    "    \n",
    "# dataframe = dataframe.drop(\"search_city\", axis=1)\n",
    "#dataframe = dataframe.drop(\"search_rigion\", axis=1)\n",
    "#dataframe = dataframe.drop(\"search_model\", axis=1)\n",
    "#dataframe = dataframe.drop(\"search_year\", axis=1)\n",
    "#dataframe = dataframe.drop(\"search_volume\", axis=1)\n",
    "#dataframe = dataframe.drop(\"search_milleage\", axis=1)\n",
    "#dataframe = dataframe.drop(\"search_price\", axis=1)\n",
    "#dataframe = dataframe.drop(\"search_year\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframe[\"a\"] = dataframe.apply(lambda row: (row['search_volume'] + 1)/(row['search_milleage']+1),axis=1).astype(float)\n",
    "dataframe[\"b\"] = dataframe.apply(lambda row: (row['search_volume'] + 1)/(row['search_price']+1),axis=1).astype(float)\n",
    "dataframe[\"c\"] = dataframe.apply(lambda row: (row['search_volume'] + 1)/(row['search_year']+1),axis=1).astype(float)\n",
    "dataframe[\"d\"] = dataframe.apply(lambda row: (row['search_milleage'] + 1)/(row['search_volume']+1),axis=1).astype(float)\n",
    "dataframe[\"f\"] = dataframe.apply(lambda row: (row['search_milleage'] + 1)/(row['search_price']+1),axis=1).astype(float)\n",
    "dataframe[\"e\"] = dataframe.apply(lambda row: (row['search_milleage'] + 1)/(row['search_year']+1),axis=1).astype(float)\n",
    "dataframe[\"g\"] = dataframe.apply(lambda row: (row['search_year'] + 1)/(row['search_volume']+1),axis=1).astype(float)\n",
    "dataframe[\"h\"] = dataframe.apply(lambda row: (row['search_year'] + 1)/(row['search_price']+1),axis=1).astype(float)\n",
    "dataframe[\"i\"] = dataframe.apply(lambda row: (row['search_year'] + 1)/(row['search_milleage']+1),axis=1).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 200\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_data = dataframe.drop(\"search_marka\", axis=1)          # data: Features\n",
    "Y_data = dataframe[\"search_marka\"]                       # data: Labels\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, test_size=0.2, random_state=0)\n",
    "\n",
    "X = X_train.drop(['user_id'], axis=1).values\n",
    "X_test = X_test.drop(['user_id'], axis=1).values\n",
    "Y = Y_train.values\n",
    "Y_test = Y_test.values\n",
    "\n",
    "# encode class values as integers\n",
    "uniques_train, ids_train = np.unique(Y_train, return_inverse=True)\n",
    "uniques_test, ids_test = np.unique(Y_test, return_inverse=True)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_train = np_utils.to_categorical(ids_train, len(Y_data.unique()))\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_test = np_utils.to_categorical(ids_test, len(Y_data.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "class EarlyStoppingByLossVal(Callback):\n",
    "    def __init__(self, monitor='val_loss', value=0.00001, verbose=0):\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
    "\n",
    "        if current > self.value:\n",
    "            if self.verbose > 0:\n",
    "                print(\"Epoch %05d: early stopping THR\" % epoch)\n",
    "            self.model.stop_training = True\n",
    "callbacks = [\n",
    "    EarlyStoppingByLossVal(monitor='val_acc', value=0.92, verbose=1),\n",
    "    # EarlyStopping(monitor='val_loss', patience=2, verbose=0),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define baseline model\n",
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(X.shape[1]-1, input_dim=X.shape[1], activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "#     model.add(Dense(X.shape[1]*2, input_dim=X.shape[1], activation='relu'))\n",
    "#     model.add(Dense(X.shape[1], activation='relu'))\n",
    "    model.add(Dense(round(X.shape[1]*2.5), input_dim=X.shape[1], activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(round(X.shape[1]*2.5), input_dim=X.shape[1], activation='relu'))\n",
    "#     model.add(Dense(X.shape[1]-1, activation='relu'))\n",
    "#     model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(len(dataframe['search_marka'].unique()), activation='softmax'))\n",
    "#     model.add(Dense(3, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7999 samples, validate on 2000 samples\n",
      "Epoch 1/3000\n",
      "7999/7999 [==============================] - 456s - loss: 4.9048 - acc: 0.0085 - val_loss: 4.8486 - val_acc: 0.0165\n",
      "Epoch 2/3000\n",
      "7999/7999 [==============================] - 394s - loss: 4.2290 - acc: 0.0756 - val_loss: 3.2081 - val_acc: 0.2405\n",
      "Epoch 3/3000\n",
      "7999/7999 [==============================] - 375s - loss: 2.7942 - acc: 0.3069 - val_loss: 2.2043 - val_acc: 0.4740\n",
      "Epoch 4/3000\n",
      "7999/7999 [==============================] - 374s - loss: 1.8700 - acc: 0.5029 - val_loss: 1.4899 - val_acc: 0.6295\n",
      "Epoch 5/3000\n",
      "7999/7999 [==============================] - 372s - loss: 1.3299 - acc: 0.6212 - val_loss: 1.3122 - val_acc: 0.6705\n",
      "Epoch 6/3000\n",
      "7999/7999 [==============================] - 371s - loss: 0.9578 - acc: 0.7223 - val_loss: 0.9889 - val_acc: 0.7630\n",
      "Epoch 7/3000\n",
      "7999/7999 [==============================] - 372s - loss: 0.7102 - acc: 0.7887 - val_loss: 0.9100 - val_acc: 0.7655\n",
      "Epoch 8/3000\n",
      "7999/7999 [==============================] - 372s - loss: 0.5372 - acc: 0.8340 - val_loss: 0.8126 - val_acc: 0.8100\n",
      "Epoch 9/3000\n",
      "7999/7999 [==============================] - 373s - loss: 0.4409 - acc: 0.8671 - val_loss: 0.7696 - val_acc: 0.8120\n",
      "Epoch 10/3000\n",
      "7999/7999 [==============================] - 374s - loss: 0.3721 - acc: 0.8865 - val_loss: 0.8768 - val_acc: 0.7790\n",
      "Epoch 11/3000\n",
      "7999/7999 [==============================] - 373s - loss: 0.3115 - acc: 0.8972 - val_loss: 0.7403 - val_acc: 0.8180\n",
      "Epoch 12/3000\n",
      "7999/7999 [==============================] - 374s - loss: 0.3002 - acc: 0.9074 - val_loss: 0.7756 - val_acc: 0.8315\n",
      "Epoch 13/3000\n",
      "7999/7999 [==============================] - 373s - loss: 0.2567 - acc: 0.9201 - val_loss: 0.7329 - val_acc: 0.8365\n",
      "Epoch 14/3000\n",
      "7999/7999 [==============================] - 374s - loss: 0.2412 - acc: 0.9207 - val_loss: 0.7697 - val_acc: 0.8290\n",
      "Epoch 15/3000\n",
      "7999/7999 [==============================] - 374s - loss: 0.2474 - acc: 0.9237 - val_loss: 0.7797 - val_acc: 0.8340\n",
      "Epoch 16/3000\n",
      "7999/7999 [==============================] - 373s - loss: 0.1953 - acc: 0.9361 - val_loss: 0.7094 - val_acc: 0.8510\n",
      "Epoch 17/3000\n",
      "7999/7999 [==============================] - 375s - loss: 0.2152 - acc: 0.9324 - val_loss: 0.6924 - val_acc: 0.8530\n",
      "Epoch 18/3000\n",
      "7999/7999 [==============================] - 375s - loss: 0.1829 - acc: 0.9415 - val_loss: 0.6915 - val_acc: 0.8530\n",
      "Epoch 19/3000\n",
      "7999/7999 [==============================] - 372s - loss: 0.1648 - acc: 0.9467 - val_loss: 0.6844 - val_acc: 0.8470\n",
      "Epoch 20/3000\n",
      "7999/7999 [==============================] - 374s - loss: 0.2008 - acc: 0.9375 - val_loss: 0.6842 - val_acc: 0.8560\n",
      "Epoch 21/3000\n",
      "7999/7999 [==============================] - 372s - loss: 0.1445 - acc: 0.9564 - val_loss: 0.6992 - val_acc: 0.8585\n",
      "Epoch 22/3000\n",
      "3400/7999 [===========>..................] - ETA: 217s - loss: 0.1473 - acc: 0.9535"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-3682969d6ad7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbaseline_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdummy_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdummy_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\envs\\dlwin36\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    868\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 870\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    872\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\dlwin36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m   1505\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1506\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1507\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\dlwin36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[0;32m   1154\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1155\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1156\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1157\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1158\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\dlwin36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2267\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2268\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2269\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2270\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\dlwin36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\dlwin36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\dlwin36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\dlwin36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\dlwin36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = baseline_model()\n",
    "model.fit(X, dummy_train, batch_size=50, epochs=3000, validation_data=(X_test, dummy_test), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)\n",
    "corrected_pred = uniques_test[numpy.round(pred).argmax(1)]\n",
    "accuracy_score(Y_test, corrected_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=20, batch_size=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, dummy_y_test, batch_size=32)\n",
    "print('Accuracy score = {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7999, 3643)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
